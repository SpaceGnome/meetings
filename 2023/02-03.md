# January 20, 2023

## Logistics

12-1 PM EST / 9-10AM PST / 5-6PM GMT

## Agenda

* Bots in Enterprise (30 mins)

## Resources

* [Minutes](https://docs.google.com/document/d/16GQd_cqzMNZtbMO04hjleihQNTYCUnpwE26FJcQDzPA/edit?usp=sharing)
* [Chair Slides](https://docs.google.com/presentation/d/1q0b0sTrEksurvD7L15-DthllFDX0b46H9Y_pxxXjekU/edit?usp=sharing&resourcekey=0-Tfydlh5sAezvH94s8wpVxw)
* [Bots Mitigation](https://drive.google.com/file/d/1ZXa1fSfUNFH_QPjUO2cI7KJqIZRWcIns/view?usp=sharing)

## Minutes

Sofia: Minutes are public on github.

Sofia: As a reminder, there’s an update on how we adopt the Private Token workstream, please send any feedback to the mailing list. \
 \
**Bot Mitigation**

Ido: Hello, thank you for letting us present here. My name is Ido Lavi and here with Ben Baryo.

We are from HUMAN security and will share the kinds of attacks/attackers we see and our bot mitigations and thoughts for the future.

HUMAN Security has many products that tackle different bot use cases. You’ve heard about Advertising/IVT/Malvertising. Today we are going to focus on enterprise solutions for detecting automated fraud.

Its not hard to get into the botting business. Look at network requests and recreate them using curl/python. Easiest attacks for account takeover/fraud are just to resend requests. To combat, security vendors load content dynamically and require values from one request to appear in another to avoid replay.

Attackers started to figure out those values and include them in their malicious requests, going through page by page to make legitimate flows. Allows attacks such as putting items into carts to reduce availability. Security vendors look for indicators that the requests don’t come from real browsers.

Attackers then started using real browsers using automation tools. Browser automation allows them to keep attacking at scale.

With the browser now used by attackers, vendors need a way to tell real person from bot, vendors using human interaction (preferably the include recognition). How users interact with browsers moved from UI/UX to security as well.

To tackle these challenges, attackers moved on to attacking the security vendors directly (changing how the JS is executed) and real humans (captcha farms) and recompiled browsers to avoid mitigations. These are the current parts of the cat and mouse game of fraud happen.

Ben: Three main challenges about trust.\

Can we trust the running environment: that the site is loaded correctly, … Some attackers are posing as victims by mimicking their whole environment, some attackers modify the JS native code.

Can we trust the session: Is the browser automated, device switching, session replay (with variances to appear genuine)

Can we trust the network: Are the payloads being sent/received actually what we expect or are they modified by the attacker.

Running environment is trusted via fingerprinting and finding discrepancies, slowing down the session to make it hard for the attacker to do it at scale.

Stronger efforts between security vendors and browsers can hopefully reduce the UX impact on the user and avoid needing to “hack” the browser to fingerprint and run these sorts of mitigations. They’d like for the browser to help develop APIs that allow for these sorts of detection. \
 \
Questions?

Sofia: Thank you for the presentation.

—

Philipp: The general problem of is a bot or human seems intractable at face value. Game/FPS aim bots, auction sniping bots, spam bots, etc. Have we tried to decompose the bot problem to find patterns. Are there users that are getting harmed versus attacks where its just your servers/datacenters getting harmed? \
 \
Ben: There are a couple of domains here. The easiest is malware vs server/site attacks. These are different domains with different tools (client solutions vs server solutions). Looking for malware on a device usually requires access to the device (hard to detect from the client). Other types are like bots that are user-driven. Someone activating a bot that has many instances rather than an injected script. (aimbot being the example of the former, or scripts that are meant to fill in forms faster when filling things online). For each a way to look at it is seeing what they’re trying to accomplish and work backward from there. Is it something that’s part of the user interaction or bypassing the user?

—

Borbala: What captured my attention is when you talked about how part of the effort goes into determining what the device is on the other end (real browser or not) and another part of how it is used (automated vs normal usage). How do you compare the importance of both. Is one more important/strategic. Can one replace the other or they more complementary. Do you think both will be needed in the longterm?

Ido: Attacks are changing very often, you can be a bot developer that wants to achieve something. You can achieve this goal in various methods. If you’re using automation, you may move to other ways if its detected. Its a rapidly changing landscape. There isn’t a specific goal but more the general idea of whether the request came from a real browser. We need to find indicators to help determine that.

Borbala: So its more about real browser instead of real click?

Ido: If you can detect whether its a specific library (selenium) you can catch the attack based on being controlled by a webdriver. First we need to understand if real browser would help alot.

Ben: The generation is iterative. If we didn’t detect fake browser, perhaps session info would reveal, otherwise in the HTTP part. Lots of different roadblocks to detect abnormal behavior. Defense in depth is important.

—

Nick: Attackers seem to move beyond curl requests and are mostly automating browsers. Seems to make it less impactful to have signals about it being a browser instead of python script since the attacker could easily move to automated browsers. Is that right?

Ido: Yes.

Nick: It also sounded like you want to know its a real browser.

Ben: Its not that fake browser detection is more important, but there are still attackers that use python scripts. So the extra layer helps catch those sorts of attacks where they only use browsers for part of their attack.

Nick: You pointed out that the attacker can recompile the browser/modify scripts. That seems to point us towards other types of solutions, since the browser giving APIs might be hacked if the attacker could recompile the browser.

Ben: Not all attackers recompile the browser, narrowing down the field brings a lot to the table. If we could get OS signals, that would be even better but outside of the scope of the CG. That’s the cat and mouse part of this, but we don’t see a lot of attackers doing sophisticated attacks.

—

Brian: Seems like there’s a wide spectrum of use cases that trying to mitigate specific instances would be a useless process. Focusing on the central question of is there a person operating this machine. Seems like we need some cooperation between the browser and the OS/hardware level. Argument that people won’t recompile browsers only matters for now and might not be a good long-term assumption. What are the implications of this work on automated personal bots/assistants as AI becomes more ubiquitous.

Ido: You’re right for the first question, but there’s a lot of unskilled attackers that won’t be able to make those attacks, there’s a lot of variety in attackers right now.  Our main goal is not to prevent all bot attacks in the world, but how to make it more expensive so it won’t be profitable to attack our clients. If we force our clients to do a specific flow and use resources, hopefully it won’t be profitable enough. Hopefully they’ll try to attack someone else.

Dimitris: At the end of the day, we care about the abusive behavior. Its okay for a human to use automation to achieve their individual goals. Its the abusive behavior that matters the most.

—

Aykut: If the browser has an API whether the operating party is a bot or human. Would it help in your case?

Ben: Attestation of the validity/integrity of the browser/person would help. Valuable to have a trusted party that you can trust to attest. More signals the easier to validate the user.

—

(Ian: I think that’s a good principle to capture - more signals helps and reduces attacker space.)

Borbala: It seems important to detect drivers/selenium. How sustainable is this to detect via JS?

Ido: If the browser can share information about being controlled, that would help. But since we don’t just focus on automation libraries, there are other types of attackers that reverse engineer the protocol. Requests that we think came from a specific library.

Dimitris: Important is being able to scale their operation and make it economically profitable for them. The trust between real browser and service is super important.

(Ian: Wonder if this has been reviewed for usefulness to these use cases: https://github.com/antifraudcg/proposals/issues/8 )

Borbala: Seeing rise in abuse for automation/puppeteer sorts of attacks.

—

Steven: We’ve heard of these types of attacks, but we are hearing that there are common attacks where browser running in a VM; and those attacks are easier to scale. Run a script for 100s of VMs on the dollar. Have you thought about how to mitigate that use case?

Ido: Basically yes we see that sort of thing, you can also just run real devices through residential proxies and use python/curl. We don’t necessarily want information about the environment is running in. The main problem is trying to figure out whether the HTTP request came from a real browser. How can we understand that the request came from a browser.

Ben: The issue here is whether the browser knows its a real person. Maybe that is something that can be handled in the browser level? Maybe if there’s not an automation protocol, it can make inferences/detect and send a signal. There’s always the recompile a browser, but it will make it more expensive.

—

Philipp: Wanted to add to Brian’s point. Attesting to whether there’s a person there is one way, but maybe detecting new device is useful, where the faking a new device is as expensive. There’s a tension between equity of access and affordability of attacks. Maybe an interesting space to explore?

Ben: Making emulators more expensive? \
 \
Philipp: Maybe PAT/rate limited sort of token.

Ben: Like some currency you have to pay with your device, and that makes it more expensive to scale on a single device.

Philipp: More like along the lines that a particular device has a namespace that could be used to rate limit how often a particular device does a particular action (and you have information about what a reasonable rate of engagement is).

Ido: We do that based on data we have, trying to attack levels of volume, but it would be useful to get more specific data.

Philipp: Depending on the problem domain, and how you react to problem patterns and whether that’s complete blocking or minor friction for real users. Hopefully there’s some combination that stops scaled abuse but not individual users.

—

Martin: I’m a product architect for Akamai’s bot product. Interesting to hear that HUMAN has a similar perspective to our threat research team. One thing is that the entire internet is not just browsers and bots, there’s also needing to support native apps/TVs/IoT devices/cars/etc. There’s even a split in bots between those that declare themselves and that don’t. Some tell they’re curl or can be detected, but otherwise more advanced headless browsers. Also seeing hybrid approaches where users install extensions to speed up their workflow. We have to aim to cover the entire fleet of user agents, not just the latest browsers or vanilla browsers. Have to get some amount of data from different clients in different ways based. Lots of different complexities and classes of user agents. \
 \
Ben: Fragmentation is definitely an issue, but as more browsers update automatically, hopefully at least the problem with updated browsers will alleviate their problems, and while we still have to support non-updated/IoT. I don’t see how that will change soon.

Martin: It still leaves some complexity on security product developers to support old browsers/clients. Can’t assume all clients have access to these APIs.

Ido: Most ecommerce/etc come from desktop/browser environments, which is why there’s a focus on browsers.

—

Aram: Caution against arms race looking at browser/OS signals. There’s a lot of sense in some of the flows discussed with tokens, sites doing attestation, and providing a means that is more privacy compliant. There’s a danger on looking at a purely mechanical problem. There’s the problem of equity of access (older OS or cheaper machines) can cause people’s life harder and their ability to make a living. Its even worse when you consider the properties that will create fraudsters. On the other side of this are people form whom successfully defrauding a website is the difference between eating lunch or not. It’s easy to emulate a system and browser. And we’ve seen big rooms full of devices controlled by humans to create fraud. The danger you create when approaching this mechanically, you are approaching this as an engineer from a western country. Arms racing with people with a very different type of stake in the problem from you will be be an eternal confrontation, pushing people towards means that are just harder to detect and potentially more harmful. 

Aram: The engineering mindset approach to this is a trap. We are trying to solve a non-machine problem with machines/algorithms. As we consider approaches to take to this, the question of equity of access and impact need to be considered significantly. At the end of the day we don’t want to create a situation where we are incentivizing or pushing for worse fraud while making life harder for the very types of people who can be pushed towards committing fraud by our actions. I’m not sure the value of these things, especially when creating signals that are bad for privacy in general. Wise to be cautious in our approach, since the other side of this equation is incentivized differently from the people in this room.

—

Sam: Today fraud prevention doesn’t rely on one-off silver bullets. Instead you see waves of fraud attacks targetting specific organizations, and responding to them relies on looking at the characteristics of the attack to find indications of the repetitive workflow. Given we have signals right now, we can look at that and have the visibility to detect these patterns. Losing those means we have to engineer new silver bullets or change the landscape significantly. Related technology that has some use is behavioral biometrics. Using the rate of click/path of mouse/etc. Useful even for not bots, since if I’m trying to steal lots of information, consistent user flows are detectable here. Unfortunate thing is that behavioral biometrics act as similar fingerprints for individuals. Concerned about losing entropy, but also that fraud prevention techniq        ues might get out of control.

Dimitris: Scared that the signal we get via behavorial biometrics, that with generative AI models that fraudsters will use that to make it much harder to distinguish behavior from bots. Still need a way to trust the behavior the user did and the device to distinguish good from bad behavior.

Sam: Long-term we’ll see those attacks, but currently the economics aren’t great for it.

—

Brian: I agree with Aram, but I thought the move was towards there being a divide between those who have the means to have technology/devices that can prevent fraud and those who can’t afford them. This potentially creating a divide between the haves and havenots. Does HUMAN look at the interaction models being used by customers to redesign them to be less prone to fraud? Looking at it from the other end of the equation.

Dimitris: We do that a lot with different customers, we have different solutions for different use cases. Sniping use case for purchases, building bespoke solutions to solve the problem. That turns out to be extremely valuable.

Brian: Techniques in the browser that can be standardized to help everyone? \
 \
Dimitris: Maybe boils down to building trust in different layers of our interaction with the device.
