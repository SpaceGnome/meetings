# April 29, 2022

## Logistics

12-1 PM EDT / 9-10AM PDT / 4-5PM GMT

## Agenda

* CG Updates (5 min)
* Device Integrity Attestation (15 mins)
* Proposals Discussion (10 mins)

## Resources

* [Minutes](https://docs.google.com/document/d/1tGOUoG8qySYBFBSl1qcTBUI5GodXHeChPKdkGIbq9rk/edit?usp=sharing)
* [Chair Slides](https://docs.google.com/presentation/d/1N-CuZ9RCz52qExF0ZxWhfZ5lyW0O3uH92RBeWf0_iXg/edit?usp=sharing)
* [Device Integrity Attestation](https://docs.google.com/presentation/d/1YZjDE5rLcKg-syAh9UiaBmSGGKjzp7vkFx4su-KvFNM/edit?usp=sharing&resourcekey=0-ZplopiNRKElHcKbD-hy1qg)

## Minutes

**Meeting cadence reminder**

SV: Every other week roughly.

**CG Updates**

SV: Welcome new co-Chairs: Mohamed Allibhai, Sofia Celi

Mohamed: Hi all. I am with Human Security; based on West Coast

Sofia: Cryptographer; joining Brave.

Steven: I’m at Google working on Chrome Privacy Sandbox. 

**Device Integrity Attestation**

Philipp: We prepared some slides. We want to know whether we are running on “actual devices.” Android and iOS have APIs for this purpose - device authenticity and integrity. How do they work?

Philipp: When you want to attest platform integrity, your service passes a nonce to an API on the device that goes into an attestation module (e.g., in a secure enclave). Takes nonce and some data and sends it to the attestation server. If it all checks out, the service signs the data including the nonce. The signed attestation is returned to the app server, which verifies the signature and makes a judgment call based on the information received. So the question is: can we do something similar with a browser?

Philipp: Similar flow for browser where browser is the entity that passes data and nonce to an attestation module.

Philipp: What do we ideally want to attest? Two large groups of properties: device set-up and device behavior. Regarding set-up: are we actually running on the device that we think we are running on? Have critical parts of the OS been modified? Is the device configuration safe (e.g., software patches? Fresh antivirus checks?)

Philipp: After set-up: is the browser modified? Are taps coming from a human? Has this device been in a good state for a long time? Can we reason about it as a device that looks like it’s being used by a human? Or is this device being used in a proxy attack?

Philipp: Lastly, we want a proof of uniqueness. What is the cardinality of unique devices within a set of requests?

Philipp: This is not an exhaustive list of properties; just a starting point.

Philipp: Challenges we face: (1) major platforms lack attestation capabilities. (2) current implementations are expensive to call; more than 1s latency won’t work for some use cases (3) What attestation capabilities do we need for the CG’s use cases? (4) What is the quality of existing attestations? (5) How can we adapt this to the Web (e.g., per-web-service v per-app information).

Philipp: Potential next steps:



*   Enumerate attestation capabilities needed for CG use cases; may be different on different platforms.
*   Identify criteria for specific use cases (e.g., latency, accuracy, coverage)
*   Identify and engage on key coverage gaps; there are many gaps at the current time.
*   Design, implement, expand

Philipp: Timeline? Based on YouTube experience, likely years.

Vacha: Do you know whether these are all present in the iOS/Android attestations?

Philipp: Can’t speak with confidence on coverage. Would be preferable to find an Apple person. The objectives of both iOS and Android are the same.

Borbala: Android includes support for features named in the slides; we could start a wish list. My intuition is that this concept generalizes well across platforms. I think a large percentage of these capabilities would be feasible. 

BrianMay: What are dependencies on server-side? How much relies on client v. server?

Philipp: My instinct is that something specific like how email has been fetched may be hard to generalize. My guess is that we will want to focus on general patterns and not application-specific behaviors (e.g., Tinder swipe v. email).  Would be good to interpret on-device data (for privacy reasons). Device manufacturers may have to help develop models based on expected behaviors.

Brian May: models that are device based

Philipp: Doesn’t have to happen on device. But it makes sense to start with on-device.

Borbala: The platform doesn’t know the semantics of applications. But things like “has this device been active for how many days in the past month?” Screen on time? Good to gather data that is not too privacy invasive. We want to translate overall device behavior into an integrity signal. Another angle at the level of the app is “is the user behaving as I would expect in my app?”

SamJackson: Thank you for the presentation. Thinking about making this work at device level v. browser level..the OS is not in the hands of the user, but browsers are often open source. Can we trust interaction between browser and attestation server if not happening in OS?

Philipp: I think the answer there is “it depends (and varies).” Depends on how applications are handled on the device. For example, is there an app store? May be different in Linux or side applications. It might be possible for platforms where apps are not bundled that there could be integrity checks on OS and run-time. 

SamJackson: Presuming that some attestation is pushed to device, or even if in the browser, do you think this would create a monopoly on tracking?

Philipp: It’s important that this not become any sort of tracking vector. There need to be assurances in the device to limit entropy. Some principles, including should not introduce tracking vectors.

MartinMeyer: Re: granularity. How much can you get for things you’ve attested to? E.g., could one interaction get multiple attestations e.g., verified hardware, verified browser, verified OS. Or could you communicate a subset?

Philipp: Interesting question. Regarding granularity of outputs; many devs may not need to or want to look at details just high level summary. And in the interest of privacy, may not want to give granular mismatches. There might be different modes (e.g., fast v. slow for time-consuming checks). 

MartinMeyer: As far as fingerprinting vectors; for the purpose of antifraud it’s very useful to detect attack signatures and try to defend against them. Users may have different levels of tolerance for different use cases (e.g., simple search v. money transfer). 

Philipp: We look for singularities (e.g., OS all 3 patches behind). I am hoping that people can make use of singularity in aggregate rather than fine-grain.

MartinMeyer: Could reduce fingerprinting if there were machine-readable data of known vulnerabilities that could be ingested by anti-fraud software.

Philipp: Let’s talk more about that to see what we might do on public vulnerability lists.

Nick Doty: I’d like to talk more in detail about bringing this to the Web. I think the browser is under the user’s control (e.g., may add extensions; may use assistive technology, etc.). What level of attestation would be wanted for browsers that are user-modified.

Borbala: The thinking is that if we have confidence that the browser is “truthful” then we can build on that and ask the browser for in-browser details. So we establish device confidence first, then ask the browser.

Philipp: Depends on the verification mechanism. “Is this browser what it presents itself as being?” If the browser declares itself to be something it’s not, that’s a signal. But it depends on the ability of the OS to verify packages. But for, e.g., compiled applications, the integrity checks will be bespoke to the browser. Only a browser will know what it’s integrity looks like. 

Nick Doty: I’m interested in what “should look like” means? I am hoping for a future where most users can install browser extensions. So there will be many browser configurations. What does a browser need to assert about user-initiated modifications?

Philipp: Good question that we need to explore more. I also want to avoid judgment in referring to modifications – some will be good and some won’t be.

Borbala: Platform can tell you what browser type and signing certificate. Based on those, you can check who signed it. You can decide if it’s something you want to accept.

SH: How do these systems evolve in the long term? How do we provide escape hatches when a user’s device is in a state where it can’t be reliably used (by malware, for example)?

Philipp: Good question; we don’t want to increase e-waste. A majority of devices are out-of-date and don’t have security patches. It might be a “let’s get this out there” first, then in a few years rely on the system for specific use cases. I agree we’ll want to avoid invalidating a lot of devices; you don’t want to alienate your customers.

Sandro Pireno: When we think of attestation modules, how do we think of this as an ecosystem of ideas? Especially with what’s going on in EU regulation, we will need to prove non-bias and make things more open source. But this might allow a fraudster to know what signals are being used to validate/invalidate a device. Would algorithms be closed but users can opt-in? Or open?

Philipp: Not sure if the Android folks have concrete opinions. My personal opinion is that we benefit from a world where many devices can attest to their integrity of not being modified. It would be good if more devices could provide that type of attestation, which turns out to be quite bespoke. Building to a standard of what checks are possible, would be a healthy situation to move towards. 

Sandro: I was thinking more of the behavior side (e.g., time between clicks). If fraudsters know how things work, will they work around the checks?

Philipp: As we build up models; the data is radioactive. We would like to not know details. If we could train models across devices, that would help learn “what is normal” and help identify aberrations, which are malicious, etc. I think that’s the healthiest pattern – mesh of devices, and figuring out which aberrations are malicious.

Borbala: +1 to the opt-in side of such modeling. Each attestation provider should make clear which parts are on by default and which are opt-in.

Aram Zucker-Scharff: I feel like we may be focusing on the wrong part of the problem. Where professionals have invested money in continuing (malicious) operations, e.g., click fraud, they will be very motivated to compromise protections in order to fake signals. But on the flip side, users who will be prevented from accessing parts of the web (for a variety of reasons), the burden is much higher. E.g., because I test ads, I am often marked as “inhuman” which makes it more difficult to do day-to-day activities [with those browsers]. In short, people most incentivized to commit fraud will also be incentivized to compromise attestations.

Philipp: I agree that the advanced attacks we see today are driven by malware. The reason we are here today is that we’ve gotten good at detecting idiosyncratic behavior. The thing I’m worried about – as privacy initiatives make detection of those behaviors harder, we may regress. Regarding more advanced attacks and malware, I agree it’s a hard problem (and will get worse). Problem of “who fixes malware” is becoming more pronounced. My hope is that we will make more explicit the role the OS plays in combating malware. Regarding false positives, it is a problem. If we build in that direction, having feedback loops to learn about those false positives will be important.

Aram: I think that it’s hard to find alternate solutions. There’s a lot of money for altering signals. I wonder whether device-level behavior is not all we want to look at. What I would challenge is that the existing antifraud processes that are going away “work”. In ad tech fraud there are estimates that between 2-98% of ad display activity is fraudulent; conservative estimates are 30-60% is fraudulent. So current approaches are not sufficient for the fraud use cases.

Philipp: Talking to the device will give more confidence than just asking browser.

Brian May: Are people looking at Federated Learning: (e.g. https://ai.googleblog.com/2017/04/federated-learning-collaborative.html)?

Philipp: I don’t think so yet; seems useful.

Ian: Tracking the chain of trust among software might be relevant here, given open source was mentioned: https://openssf.org/

**Proposals Discussions**

Steven: See the proposals that are emerging. For any other open issues, it would be good to get more solid documents that can live in their own repos. 

Use cases: ​​https://github.com/antifraudcg/proposals/blob/main/use-cases/use-cases.md 

Other proposals: 



*   Fraud prevention trusted server
*   Device attenstations
*   Overlapps of payment fraud

Meeting in two weeks. Join slack and discuss: More going on in slack!