 # October 28, 2022

## Logistics

12-1 PM EDT / 9-10AM PDT / 4-5PM GMT

## Agenda

* Proposal Review (40 mins)


## Resources

* [Minutes](https://docs.google.com/document/d/1RHraUi2rGyunw9dpRwOEDixAkJMKul0cTwc_7BJHAtI/edit?usp=sharing)
* [Chair Slides](https://docs.google.com/presentation/d/1CKc3Rv-oUjelfFY3IQR8YUMur6Adi7aFAVtJejhF2iE/edit?usp=sharing)

## Minutes
General structure of meeting is different. 3-5min on each proposal, and looking for feedback. Whether people are interested in picking up and doing more work on them. Use queue in doc.

Next CG meeting on Nov 11. Nov 25 will be canceled due to Thanksgiving week in the US.


## Proposal review

Device Mesh: https://github.com/antifraudcg/proposals/issues/17



*   Steven: Identify suspicious activity on a group device. “Mesh” is so a single malicious device can not provide signals for questionable activity. Also provides privacy property. There is a question of what sorts of signals this could provide, or what are available. Any thoughts on this proposal?
*   Brian May: I think it’s worth pursuing what use cases might apply, and whether we can provide adequate guarantees for it. There are applications outside of anti-fraud; such as clients/user-agents that provide information for a population while preserving privacy.
*   Nick Doty: I would appreciate it if there is an implementation done on this. Seems extremely complex. Has anyone put it into practice before we work on it.
*   Steven: AFAIK, there hasn’t been an actual implementation of this, still in ideation stage.
*   Ian Jacobs: Seems to be based on shared consensus without sharing individual information, can you say more?
*   Steven: Proof of general identity (e.g. country). One of things we need to do early is to identify use cases and specific signals that we want to provide.
*   Sam : How do we provide feedback if we find out that that’s not a true identity?
*   Steven: Current proposal doesn’t have a mechanism, but that might be feedback to provide.
*   Thiago: Talked to a partner in LatAm who is interested in this. For example, the mesh could be provided without needing a server. I think we should discuss this more.
*   Steven: Chairs will respond to each proposal with a summary of this discussion, but encourage this group to add comments to the proposals.

Fraud prevention trusted server: https://github.com/antifraudcg/proposals/issues/3



*   Philipp: Basic idea of a trusted server (e.g. Amazon Nitro enclave) - can it be part of a solution? Up to the group. Similar to the mesh problem. Being able to say that it’s provable that this operation happened. Right now, proposal is phrased as a solution looking for a problem, so not sure.
*   Steven: Are others in the group interested in pursuing this?
*   Aram: Interesting idea. Very vague right now, but possible route that syncs with the work happening in private trusted ad execution/measurement. Makes sense to have a private trusted fraud mechanism. This thread seems to be about conceptual exploration; which I am supportive. Maybe generating a report would be something useful for us to do.
*   Brian: I also think so. As Aram suggested, there is work being done in other quarters, from which anti-fraud can benefit from/contribute to.
*   Nick: is this a separate proposal, or a potential architecture feature of many proposals? Things like Trust Tokens, Device Attestations, etc? 
*   Steven: The question is if a TEE/trusted server can be given access to more information to provide anti-fraud signals.
*   Philipp: To provide context, this was proposed by an engineer who’s building a trusted server for FLEDGE. This engineer suggested that maybe there would be applications for anti-fraud; so we put it out there as an idea that might benefit other proposals so definitely latter category.

Camera integrity authentication: https://github.com/antifraudcg/proposals/issues/13



*   Steven: In LatAm/other areas, cameras are used to ascertain identity. So it would be useful to know the camera’s integrity.
*   Will: I read this with a lot of interest, since I am dealing with this reasonably frequently. We see this in a product a couple thousand times a day, if not more. The challenge is that there are genuine hardware cameras that can stream modified imagery. I’m not sure of the value of this, and whether it actually helps those doing anti-fraud.
*   Aram: Will bow to exports on this one; but will note that this and other proposals are referencing privacy/security/fraud implications in LatAm. Might be good to have a session about challenges from implementers in that region. Would be good to have a session/report from folks in that region.
*   Nick: I would certainly welcome input from them. I am generally skeptical of these DRM-style mechanisms that prevent the user from controlling their own device/software. Hard to enforce, and potentially harmful for many users in many situations,
*   Brian: Feels out-of-scope for this group. Not that we wouldn't take advantage of the capability if someone created it. Would need camera manufacturers to provide it.
*   Philipp: If anyone is interested in this, looking at the broader category of sensor attestation might be helpful. Some work has been done for fingerprint sensors.
*   Steven: [with chair hat on]: A lot of this problem is out-of-scope for W3C. If there is interest in that line, there is a question for the W3C about whether that signal can be exposed to the web; but we can’t do anything about the first step.
*   Panos: Yeah, not sure if a signal is available that can be trusted by browser without a TEE.
*   Thiago: +1 to what Panos said. I can also talk to this company for more clarity and how this works in practice; and then we can discuss next steps for this proposal.
*   Steven: Learning if there is a subset of the problem we can actually work on, we can work on it, but lots of privacy questions to discuss. But getting clarity is a good next step.

Device Integrity through the browser: https://github.com/antifraudcg/proposals/issues/8



*   Philipp: We’ve learned a lot from this group. Thank you. Need to think about cross-platform behavior. Having some control over http (?) would be good. No public updates at this time.
*   Steven: Not really an API; but should we continue ideating on signals. Get other platforms involved?
*   Brian: SImilar to the last one, if there is device support, I think device attestation is even more valuable to a broad range of usecases; but needs hardware/OS support. Might need to wait for them to catch up.
*   Steven: Would people in the CG like to pull in folks from that space; or better to have those conversations in side meetings?
*   Brian: Would presume that there might be interest from user agents (OS/platforms) in developing. Seems like a lot for this group to take on, given the size of te group and the focus.
*   Will: On this sort of device/camera integrity, might be able to take some work of the Secure Payment Confirmation (SPC) work. They’re talking about doing things w/ DLLs and such on Windows for device integrity. Panos and I have worked with them in the past.
*   Ian: As SPC person, I can say that we’re punting on this question to FIDO. SPC brings a user dialog that’s easy to understand. Wondering if it’s easy to re-use that model.

Anti-fraud Safelists: https://github.com/antifraudcg/proposals/issues/4



*   Sam: Idea is that browser manufacturers maintain safelists of certified parties that view much more unobfuscated details (such as IP addresses). SImilar to CAs. They would have to certify that it’s used for things like anti-fraud; and not for other things. Only possible for them to collect signals in high-risk contexts like login/payments. USer could edit that list. They can get prompts in high-risk contexts if they prefer more control. The real thrust is to minomize disruption to existing anti-abuse controls while building out solutions.
*   Brian: Very interesting proposal, potentially broad application. E.g advertising, differentiated (not necessarily high-risk) context. COuld be a very useful, general applicable mechanism
*   Philipp: Concerned about the administration of this list. Is there an existing model we could follow?
*   Ian: Same question for me. How does this scale across browsers? Maybe there are examples of existing lists that browsers share, but I don’t know how they work and what challenges.
*   Nick: Might be useful to split this up. If there is interest from the browsers in setting up another CA-like system (my understanding is that they probably wouldn’t be). Heard from Sam that there would be attestation from the site, which seems like a good thing to have for the privacy/security of the web. During the period where we haven’t transitioned; could be useful for browsers/users to make decisions based on this. Also regulatory overview. I would ve very interested in working on that.
*   Sam: Governance model we had in mind similar to CA.

Cross-partition cookie age signal: https://github.com/antifraudcg/proposals/issues/9



*   Philipp: For services that operate on long-tail domains in an embedded context; they can't tell the difference between a new user, vs. user visiting partition for the first time. Having a cross-partition would be useful. As folks have mentioned it’s possible to modify browsers to fake this signal. Mentally, I would ice-box this.
*   Brian: For hard-core fraud cases, probably not valuable. But for un-sophisticated users, could it not be useful? For users would create new accounts.
*   Philipp: Yeah, will leave it to the people who could use this.
*   Aram: General pro hibernating this. Attack vector isnt of high concern. Higher concern is the user generating new browsers. Not a lot of times (might be different for others) do we see attackers that couldn’t defeat this.

Private State Tokens (fka Trust Tokens): https://github.com/antifraudcg/proposals/issues/7



*   Convery information from one context to another. Renamed last week, before the name “trust” suggested that the tokens themselves contained trust which was confusing. Another proposal by Apple called “Private Access Tokens” that have similar properties. Should we consider moving “Private Tokens” into the CG and build variants of this.
*   Brian: Would be good to have something trustworthy in a future with relatively little data.
*   Nick: I think it’s useful to have the approach of someone attesting to the user’s data, rather than preventing the user from controlling their own data. Some conversation on aligning with Privacy Pass in IETF. Working on interoperability seems like a promising direction.
*   Steven: Hope is to still align with PrivacyPass, but that is WGLC in IETF. One question we have is if it’s okay to adopt the work in it’s current state, and then converge with IETF in the long-term.
*   Aram: I think this proposal is strong and useful, I see a number of uses. I am supportive of bringing this work into the CG.
*   Ian: Not following work in the IETF. Can someone say what’s needed for alignment and who needs to be talking?
*   Steven: No major standards disagreements, just engineering work to make the changes. No fundamental deltas.

Detect suspicious location behavior: https://github.com/antifraudcg/proposals/issues/18



*   Steven: Example use-case stolen phone used elsewhere. For example in payments.
*   Brian: As I indicated in the issue, I think it’s an interesting proposal; as long as it doesn’t provide more than a “yes” or “no” answer. “Is this device in a normal location?”, rather than “Is this device in &lt;given> location?”
*   Ian: Wondering if I travel, some definition of “normal” needs to take into account normal mobility. If the answer is “I know this is not a normal location; but I have other information that explains this”, that might be ok, but curious how this will be used.
*   Brian: The idea is that it would be one signal that could inform the interaction.
*   Aram: Requires a higher-level precision while applying some privacy protection. For example, I travel but my bank is able to use other data hookups to solve this. I’m not worried about his use-case. This use-case seems to be more cell-phone getting stolen in one part of the city and being used in another part of the same city. Lots of thorny privacy issues to work though.
*   Nick: I’m really grateful for the detail we’re getting on some use-cases/proposal; but scary to have that level of precision on location. Likely to have other privacy and user-control issues. But if this is one of many signals, could see some interaction.
*   Thiago: Could be useful to use TEEs. I talk to this company in Brazil. They already do this in the back-end, the proposal is to move this to the front-end. The idea is to move this logic on-device for better privacy.

Attestation of device lifetime: https://github.com/antifraudcg/proposals/issues/15



*   Steven: Some relation to cookie age signal; but more specific to device. Proposal of how to limit the fine-grainedness of the signal.
*   Aram: Agree with Brian’s comment. Lifetime of a device is a fingerprinting signal. Don’t understand why an attacker couldnt just change this, since they’re spinning up devices using headless browsers, Selenium. Seems like there is nothing in the proposal that prevents.
*   Steven: One approach might be to have a device vendor attestation to capture. 
*   Brian: Similar to my comment about the cookie age, are there applications of this usecase for average users, and not attackers who can spin up new devices.

Marking devices as a fraudster: https://github.com/antifraudcg/proposals/issues/14



*   Steven: Might raise similar questions about why an attacker couldn’t simply modify this signal. … Do extra device checking.
*   Philipp: Composability of entropy (site, embedded sites - each can set m bits; so n\*m bits) is concerning. If there’s a clever way of addressing that, would be interested.
*   Nick: Haven’t read in detail, but agree with Philipp’s comment. May be some analysis from Google’s Trust Tokens work to see if an attacker could identify. If folks just want a single private metadata bit, maybe we should bring that up on the other proposals.
*   Brian: Such a signal could be used to arbitrary identify sub-populations. Should not allow anybody to do this. If there is a way to limit this, I;d be interested in learning.
*   Aram: I suggest we proposed to the author that this be merged in with the Trust Tokens proposal. Inverse of that proposal, but many similarities. Concerns should be addressed as part of that work.

eTLD+1: https://github.com/antifraudcg/proposals/issues/12



*   Steven: Provided by client to prevent domain-spoofing attacks.
*   Nick: Is this just a referrer header, or something else?
*   Brian: Value provided by browser in coded format, used to verify a claim of an ad impression coming from the context it claims. No other information needs to be provided; just a single bit.
*   Steven: If this is going through a bid request, could anyone modify that?
*   Brian: The recipient of the bid request should be able to verify. Would just blocklist anyone doing that.
*   Aram: Sounds like something worth exploring more. Understand that a browser coild theoretically falsify the signal. But this attack doesn’t deal with fake user agents, so I think it could be a useful idea worth more discussion.

Device score calculation: https://github.com/antifraudcg/proposals/issues/16



*   Steven: Using data on the device to detect whether it’s been doing a lot of “good”/”bad” behavior, and limiting actions by that device. Lots of discussion in the FLEDGE space about this.
*   Aram: Seems like an awful lot like using device meditation to perform fingerprinting. Serious privacy concerns. Perhaps there’s a version of this with a TEE that is feasible. We should suggest that the author think about doing that to address privacy concerns.
*   Thiago: What is the concern? I can talk to them.
*   Aram: Feels like it’s doing fingerprinting in a slightly different way, on the browser. I see that they want to do this without violating privacy; but using a trusted server model instead of doing it as proposed.

Steven: Chairs to discuss next steps and follow-up. Will first give feedback to proposal authors. Prioritization will be based on responses.
